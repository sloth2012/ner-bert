{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactRuEval example (uncased model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download pretrained bert model\n",
    "Download pretrained bert [uncased](https://storage.googleapis.com/bert_models/2018_11_03/multilingual_L-12_H-768_A-12.zip), [cased](https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip) (recommended) and unzip.\n",
    "\n",
    "Use the following code for convert tensorflow model to pytorch:\n",
    "\n",
    "\n",
    "```export BERT_BASE_DIR=/path/to/bert/multilingual_L-12_H-768_A-12```\n",
    "\n",
    "```python3 convert_tf_checkpoint_to_pytorch.py \\```\n",
    "\n",
    "```  --tf_checkpoint_path $BERT_BASE_DIR/bert_model.ckpt \\ ```\n",
    "\n",
    "```  --bert_config_file $BERT_BASE_DIR/bert_config.json \\```\n",
    "\n",
    "```  --pytorch_dump_path $BERT_BASE_DIR/pytorch_model.bin```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_path = \"/home/lis/ner/ulmfit/data/factrueval/\"\n",
    "train_path = os.path.join(data_path, \"train_with_pos.csv\")\n",
    "valid_path = os.path.join(data_path, \"valid_with_pos.csv\")\n",
    "model_dir = \"/datadrive/models/multilingual_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = \"/datadrive/models/multilingual_L-12_H-768_A-12/pytorch_model.bin\"\n",
    "bert_config_file = os.path.join(model_dir, \"bert_config.json\")\n",
    "vocab_file = os.path.join(model_dir, \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.is_available(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data train and validation should be presented in the following format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>Мифология солнцеворота , собственно , и сводит...</td>\n",
       "      <td>NOUN NOUN PNCT ADVB PNCT CONJ VERB PREP NOUN N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O O O O O O B_ORG I_ORG O B_ORG I_ORG O O O O ...</td>\n",
       "      <td>По его словам , с покупкой Caramba TV « СТС Ме...</td>\n",
       "      <td>PREP NPRO NOUN PNCT PREP NOUN &lt;unk&gt; &lt;unk&gt; PNCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O O O O O O O O O O O O O O O O B_LOC O</td>\n",
       "      <td>Такое десятилетие , по его словам « необходимо...</td>\n",
       "      <td>ADJF NOUN PNCT PREP NPRO NOUN PNCT ADJS ADJF P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O O O O O O O O O O O O O O</td>\n",
       "      <td>Правительство уволило часть врачей , обвинив и...</td>\n",
       "      <td>NOUN VERB NOUN NOUN PNCT GRND NPRO PREP NOUN N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O O O B_PER I_PER O O O O O O B_ORG I_ORG I_OR...</td>\n",
       "      <td>Министр сельского хозяйства Николай Федоров пр...</td>\n",
       "      <td>NOUN ADJF NOUN NOUN NOUN VERB PNCT CONJ PRTF V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0            O O O O O O O O O O O O O O O O O O O O   \n",
       "1  O O O O O O B_ORG I_ORG O B_ORG I_ORG O O O O ...   \n",
       "2            O O O O O O O O O O O O O O O O B_LOC O   \n",
       "3                        O O O O O O O O O O O O O O   \n",
       "4  O O O B_PER I_PER O O O O O O B_ORG I_ORG I_OR...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  Мифология солнцеворота , собственно , и сводит...   \n",
       "1  По его словам , с покупкой Caramba TV « СТС Ме...   \n",
       "2  Такое десятилетие , по его словам « необходимо...   \n",
       "3  Правительство уволило часть врачей , обвинив и...   \n",
       "4  Министр сельского хозяйства Николай Федоров пр...   \n",
       "\n",
       "                                                   3  \n",
       "0  NOUN NOUN PNCT ADVB PNCT CONJ VERB PREP NOUN N...  \n",
       "1  PREP NPRO NOUN PNCT PREP NOUN <unk> <unk> PNCT...  \n",
       "2  ADJF NOUN PNCT PREP NPRO NOUN PNCT ADJS ADJF P...  \n",
       "3  NOUN VERB NOUN NOUN PNCT GRND NPRO PREP NOUN N...  \n",
       "4  NOUN ADJF NOUN NOUN NOUN VERB PNCT CONJ PRTF V...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and valid .csv files must have columns named (0, 1). Column 3 is't necessary (does not used now).\n",
    "* Column 0 contains labels in IOB format.\n",
    "* Column 1 contains tokenized and separated (by whitespace) text.\n",
    "\n",
    "For using data in model we need to create `NerData` object.\n",
    "\n",
    "* `train_path` - path to train .csv file\n",
    "* `valid_path` - path to valid .csv file\n",
    "* `vocab_file` - path to google bert pretrained vocab\n",
    "* `batch_size` - batch size (default `16`)\n",
    "* `cuda` - using cuda or cpu (default `True`)\n",
    "* `is_cls` - create data for joint model (default `False`)\n",
    "* `data_type` - type of input embeddings (default `bert`)\n",
    "* `max_seq_len` - max sequence len for BERT tokens (default `424`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=415), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For factrueval we use the following sample of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '[CLS]': 1, '[SEP]': 2, 'B_O': 3, 'I_O': 4, 'B_ORG': 5, 'I_ORG': 6, 'B_LOC': 7, 'B_PER': 8, 'I_PER': 9, 'I_LOC': 10}\n"
     ]
    }
   ],
   "source": [
    "print(data.label2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model\n",
    "For creating pytorch model we need to create `NerModel` object.\n",
    "\n",
    "* `label_size` - number of labels: `len(data.label2idx)`,\n",
    "\n",
    "BertEmbedder params\n",
    "* `bert_config_file` - path to google bert pretrained config\n",
    "* `init_checkpoint_pt` - path to google bert pretrained weights\n",
    "* `embedding_dim` - output dim from bert model (default `768`)\n",
    "* `bert_mode` - mode of how bert output will be returned. If `last` return the output of last layer. If `weighted` return weighted sum of all bert output layers, weights are learnable (aka ELMO).\n",
    "* `freeze` - freezing bert model (default `True`)\n",
    "\n",
    "BertBiLSTMEncoder params\n",
    "* `enc_hidden_dim` - dim of rnn layer or hidden layer (default `128`)\n",
    "* `rnn_layers` - number of rnn layers in encoder\n",
    "\n",
    "CRFDecoder params\n",
    "* `input_dropout` - dropout param (default `0.5`),\n",
    "\n",
    "Gpu or cpu:\n",
    "* `use_cuda` - use cuda or cpu (default `True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import BertBiLSTMCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertBiLSTMCRF.create(len(data.label2idx), bert_config_file, init_checkpoint_pt, enc_hidden_dim=128, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436161"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create learner\n",
    "\n",
    "For training our pytorch model we need to create `NerLearner` object.\n",
    "\n",
    "* `model: NerModel` - pytorch model\n",
    "* `data: NerData` - train and valid dataloaders\n",
    "* `best_model_path` - path for store best model\n",
    "* `lr` - starting learning rate (default `0.001`)\n",
    "* `betas` - params for default optimizer (default `[0.8, 0.9]`)\n",
    "* `clip` - grad clipping (default `5`)\n",
    "* `verbose` - printing to console reports (default `True`)\n",
    "* `sup_labels` - list of supported labels for calculating `target_metric` metric. For FactRuEval use: `['B_LOC', 'I_LOC', 'B_ORG', 'I_ORG', 'B_PER', 'I_PER']` (default `None`)\n",
    "* `t_total` - total optimization steps, used for lr scheduler, if -1, don't scale lr after batch iteration (default `-1`), usally t_total = num_epochs * train_size / batch_size\n",
    "* `warmup` - portion of t_total for the warmup, -1  means no warmup (default `0.1`)\n",
    "* `weight_decay` - weight decay (default `0.01`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/models/factrueval/exp_final.cpt\",\n",
    "                     lr=0.001, clip=5.0, sup_labels=data.id2label[5:],\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Learn your NER model\n",
    "Call `learner.fit`\n",
    "* `epochs` - number of train iterations (default `100`)\n",
    "* `resume_history` - resuming appending results to history or create new (default `True`)\n",
    "* `target_metric` - mean metric, that want you see to pick best epochs (default `f1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Resuming train... Current epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "epoch 1, average train epoch loss=14.153\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:on epoch 0 by max_f1: 0.342\n",
      "INFO:root:Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.435     0.181     0.256       259\n",
      "       I_ORG      0.657     0.458     0.540       506\n",
      "       B_LOC      0.320     0.286     0.302       192\n",
      "       B_PER      0.407     0.314     0.354       188\n",
      "       I_PER      0.527     0.640     0.578       136\n",
      "       I_LOC      0.500     0.012     0.023        84\n",
      "\n",
      "   micro avg      0.509     0.352     0.416      1365\n",
      "   macro avg      0.474     0.315     0.342      1365\n",
      "weighted avg      0.511     0.352     0.399      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(num_epochs - 1, target_metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict on new data\n",
    "Create new data loader from existing path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_bert_data_loader_for_predict(data_path + \"valid.csv\", learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call predict from learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform predictions to tokens and spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Сделка', 'состоится', ',', 'если', 'будет', 'одобрена', 'регуляторами', ',', 'из-за', 'которых', 'в', 'начале', 'года', 'сорвалось', 'слияние', 'NYSE', 'Euronext', 'с', 'Deutsche', 'Börse']\n",
      "['B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_O', 'B_ORG', 'I_ORG', 'B_O', 'B_ORG', 'I_ORG']\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.utils import bert_labels2tokens, tokens2spans\n",
    "\n",
    "\n",
    "tp, lp = bert_labels2tokens(dl, preds)\n",
    "print(tp[0])\n",
    "print(lp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = tokens2spans(tp, lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Сделка', 'O'), ('состоится', 'O'), (',', 'O'), ('если', 'O'), ('будет', 'O'), ('одобрена', 'O'), ('регуляторами', 'O'), (',', 'O'), ('из-за', 'O'), ('которых', 'O'), ('в', 'O'), ('начале', 'O'), ('года', 'O'), ('сорвалось', 'O'), ('слияние', 'O'), ('NYSE Euronext', 'ORG'), ('с', 'O'), ('Deutsche Börse', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "print(sp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.873     0.826     0.849       259\n",
      "       I_ORG      0.931     0.808     0.865       898\n",
      "       B_LOC      0.935     0.901     0.918       192\n",
      "       I_LOC      0.929     0.856     0.891       277\n",
      "       B_PER      0.972     0.936     0.954       188\n",
      "       I_PER      0.978     0.949     0.964       613\n",
      "\n",
      "   micro avg      0.941     0.869     0.903      2427\n",
      "   macro avg      0.937     0.879     0.907      2427\n",
      "weighted avg      0.940     0.869     0.902      2427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC      0.870     0.839     0.854       192\n",
      "         ORG      0.833     0.788     0.810       259\n",
      "         PER      0.945     0.910     0.927       188\n",
      "\n",
      "   micro avg      0.877     0.839     0.858       639\n",
      "   macro avg      0.883     0.845     0.863       639\n",
      "weighted avg      0.877     0.839     0.857       639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try cased bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "data_path = \"/home/lis/ner/ulmfit/data/factrueval/\"\n",
    "train_path = os.path.join(data_path, \"train_with_pos.csv\")\n",
    "valid_path = os.path.join(data_path, \"valid_with_pos.csv\")\n",
    "model_dir = \" /datadrive/models/multi_cased_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = os.path.join(\"/datadrive/models/multi_cased_L-12_H-768_A-12/\", \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"bert_config.json\")\n",
    "vocab_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3728), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=415), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from modules import BertNerData as NerData\n",
    "\n",
    "\n",
    "data = NerData.create(train_path, valid_path, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import BertBiLSTMCRF\n",
    "\n",
    "\n",
    "model = BertBiLSTMCRF.create(len(data.label2idx), bert_config_file, init_checkpoint_pt, enc_hidden_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Use lr OneCycleScheduler...\n"
     ]
    }
   ],
   "source": [
    "from modules import NerLearner\n",
    "\n",
    "\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/models/factrueval/exp_final_cased.cpt\",\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label[5:],\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(100, target_metric='prec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.845     0.842     0.843       259\n",
      "       I_ORG      0.920     0.836     0.876      1000\n",
      "       B_LOC      0.927     0.865     0.895       192\n",
      "       I_LOC      0.915     0.818     0.864       303\n",
      "       B_PER      0.973     0.957     0.965       188\n",
      "       I_PER      0.984     0.957     0.970       649\n",
      "\n",
      "   micro avg      0.933     0.876     0.903      2591\n",
      "   macro avg      0.927     0.879     0.902      2591\n",
      "weighted avg      0.932     0.876     0.903      2591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "\n",
    "\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC      0.850     0.797     0.823       192\n",
      "         ORG      0.812     0.815     0.813       259\n",
      "         PER      0.908     0.894     0.901       188\n",
      "\n",
      "   micro avg      0.851     0.833     0.842       639\n",
      "   macro avg      0.857     0.835     0.845       639\n",
      "weighted avg      0.852     0.833     0.842       639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict\n",
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "\n",
    "\n",
    "dl = get_bert_data_loader_for_predict(data_path + \"valid.csv\", learner)\n",
    "\n",
    "preds = learner.predict(dl)\n",
    "\n",
    "clf_report = get_bert_span_report(dl, preds)\n",
    "print(clf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
