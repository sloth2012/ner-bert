{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conll 2003 nmt evaluation\n",
    "\n",
    "Data downloaded from [here](https://github.com/kyzhouhzau/BERT-NER/tree/master/NERdata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/datadrive/conll-2003/\"\n",
    "\n",
    "train_path = data_path + \"train.txt\"\n",
    "dev_path = data_path + \"dev.txt\"\n",
    "test_path = data_path + \"test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prc data for csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"Reads a BIO data.\"\"\"\n",
    "    with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = []\n",
    "        words = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            contends = line.strip()\n",
    "            word = line.strip().split(' ')[0]\n",
    "            label = line.strip().split(' ')[-1]\n",
    "            if contends.startswith(\"-DOCSTART-\"):\n",
    "                words.append('')\n",
    "                continue\n",
    "            \n",
    "            if len(contends) == 0 and not len(words):\n",
    "                words.append(\"\")\n",
    "            \n",
    "            if len(contends) == 0 and words[-1] == '.':\n",
    "                l = ' '.join([label for label in labels if len(label) > 0])\n",
    "                w = ' '.join([word for word in words if len(word) > 0])\n",
    "                lines.append([l, w])\n",
    "                words = []\n",
    "                labels = []\n",
    "                continue\n",
    "            words.append(word)\n",
    "            labels.append(label.replace(\"-\", \"_\"))\n",
    "        return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = read_data(train_path)\n",
    "dev_f = read_data(dev_path)\n",
    "test_f = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[l for l in train_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 1739, 1559)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_f), len(dev_f), len(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_ORG O B_MISC O O O B_MISC O O',\n",
       " 'EU rejects German call to boycott British lamb .']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_f, columns=[\"0\", \"1\"])\n",
    "train_df.to_csv(data_path + \"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame(dev_f, columns=[\"0\", \"1\"])\n",
    "valid_df.to_csv(data_path + \"valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_f, columns=[\"0\", \"1\"])\n",
    "test_df.to_csv(data_path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/datadrive/conll-2003/\"\n",
    "train_path = data_path + \"train.csv\"\n",
    "valid_path = data_path + \"valid.csv\"\n",
    "test_path = data_path + \"test.csv\"\n",
    "\n",
    "model_dir = \" /datadrive/models/multi_cased_L-12_H-768_A-12/\"\n",
    "init_checkpoint_pt = os.path.join(\"/datadrive/models/multi_cased_L-12_H-768_A-12/\", \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"bert_config.json\")\n",
    "vocab_file = os.path.join(\"/datadrive/bert/multi_cased_L-12_H-768_A-12/\", \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.is_available(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 1739)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dl.dataset), len(data.valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '[CLS]', '[SEP]', 'B_ORG', 'B_O', 'I_O', 'B_MISC', 'B_PER', 'I_PER', 'B_LOC', 'I_LOC', 'I_ORG', 'I_MISC']\n"
     ]
    }
   ],
   "source": [
    "print(data.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_labels = ['B_ORG', 'B_MISC', 'B_PER', 'I_PER', 'B_LOC', 'I_LOC', 'I_ORG', 'I_MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(f.labels_ids) for f in data.train_dl.dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertBiLSTMAttnNMT.create(len(data.label2idx), bert_config_file, init_checkpoint_pt,\n",
    "                                 enc_hidden_dim=128, dec_hidden_dim=128, dec_embedding_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: fix bug with len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Don't use lr scheduler...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=\"/datadrive/models/conll-2003/bilstm_attn_cased.cpt\",\n",
    "                     lr=0.01, clip=1.0, sup_labels=data.id2label[5:],\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Start learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(num_epochs, target_metric='prec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict\n",
    "dl = get_bert_data_loader_for_predict(data_path + \"valid.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.922     0.934     0.928      1282\n",
      "      B_MISC      0.924     0.892     0.908       905\n",
      "       B_PER      0.973     0.970     0.972      1686\n",
      "       I_PER      0.985     0.974     0.980      3488\n",
      "       B_LOC      0.953     0.958     0.956      1669\n",
      "       I_LOC      0.956     0.936     0.946      1913\n",
      "       I_ORG      0.910     0.927     0.918      2129\n",
      "      I_MISC      0.860     0.838     0.849      1061\n",
      "\n",
      "   micro avg      0.946     0.940     0.943     14133\n",
      "   macro avg      0.936     0.928     0.932     14133\n",
      "weighted avg      0.946     0.940     0.943     14133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC      0.870     0.863     0.866       905\n",
      "         ORG      0.815     0.836     0.826      1282\n",
      "         PER      0.930     0.928     0.929      1686\n",
      "           O      0.990     0.989     0.990     41801\n",
      "         LOC      0.895     0.904     0.899      1669\n",
      "\n",
      "   micro avg      0.977     0.977     0.977     47343\n",
      "   macro avg      0.900     0.904     0.902     47343\n",
      "weighted avg      0.978     0.977     0.978     47343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds, [])\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict\n",
    "dl = get_bert_data_loader_for_predict(data_path + \"test.csv\", learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOB precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B_ORG      0.922     0.934     0.928      1282\n",
      "      B_MISC      0.924     0.892     0.908       905\n",
      "       B_PER      0.973     0.970     0.972      1686\n",
      "       I_PER      0.985     0.974     0.980      3488\n",
      "       B_LOC      0.953     0.958     0.956      1669\n",
      "       I_LOC      0.956     0.936     0.946      1913\n",
      "       I_ORG      0.910     0.927     0.918      2129\n",
      "      I_MISC      0.860     0.838     0.849      1061\n",
      "\n",
      "   micro avg      0.946     0.940     0.943     14133\n",
      "   macro avg      0.936     0.928     0.932     14133\n",
      "weighted avg      0.946     0.940     0.943     14133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.train.train import validate_step\n",
    "print(validate_step(learner.data.valid_dl, learner.model, learner.data.id2label, learner.sup_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC      0.758     0.778     0.768       688\n",
      "         ORG      0.656     0.683     0.669      1533\n",
      "         PER      0.864     0.859     0.861      1566\n",
      "           O      0.980     0.977     0.979     37690\n",
      "         LOC      0.834     0.851     0.843      1570\n",
      "\n",
      "   micro avg      0.955     0.955     0.955     43047\n",
      "   macro avg      0.818     0.830     0.824     43047\n",
      "weighted avg      0.955     0.955     0.955     43047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds, [])\n",
    "print(clf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
