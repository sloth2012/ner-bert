{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath('../')\n",
    "\n",
    "data_path = os.path.join(root_dir, 'datadrive/bailian')\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(data_path, 'train.csv')\n",
    "valid_path = os.path.join(data_path, 'valid.csv')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'datadrive/bert/chinese_L-12_H-768_A-12/')\n",
    "init_checkpoint_pt = os.path.join(root_dir, 'datadrive/models/chinese_L-12_H-768_A-12/pytorch_model.bin')\n",
    "bert_config_file = os.path.join(model_dir, 'bert_config.json')\n",
    "vocab_file = os.path.join(model_dir, 'vocab.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    \n",
    "    import re\n",
    "    import json\n",
    "    \n",
    "    p = re.compile(r'(.+?)/(?:([a-z]{1,2})(?:$| ))')\n",
    "    seg_file = os.path.join(data_path, 'final_baidu-23w.txt')\n",
    "    \n",
    "    delimiter='△△△'\n",
    "    with open(seg_file) as fin, open(train_path, 'w') as train_f, open(valid_path, 'w') as valid_f:\n",
    "        train_f.write(f'0{delimiter}1\\n')\n",
    "        valid_f.write(f'0{delimiter}1\\n')\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            import random\n",
    "            score = random.random()\n",
    "            \n",
    "            fout = train_f if score > 0.3 else valid_f\n",
    "            words = []\n",
    "            flags = []\n",
    "            for word, flag in p.findall(line):\n",
    "                char_list = [c if c not in [' ', '\\x7f']  else 'unk' for c in list(word)]\n",
    "                \n",
    "                tag_list = [f'B_{flag}'] + [f'I_{flag}']  * (len(char_list) - 1)\n",
    "                \n",
    "                if len(char_list) != len(tag_list):\n",
    "                    print(line)\n",
    "                    print(word, flag)\n",
    "                    print(char_list, tag_list)\n",
    "                    \n",
    "                words.extend(char_list)\n",
    "                flags.extend(tag_list)\n",
    "                \n",
    "            assert len(words) == len(flags)\n",
    "                \n",
    "            fout.write(delimiter.join([\n",
    "                ' '.join(flags),\n",
    "                ' '.join(words)\n",
    "            ]))\n",
    "            fout.write('\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "build_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from modules import BertNerData as NerData\n",
    "\n",
    "data = NerData.create(train_path, valid_path, vocab_file, data_type=\"bert_uncased\", cuda=False,is_cls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155954, 67275)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dl.dataset), len(data.valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '[CLS]',\n",
       " 'B_m',\n",
       " 'B_w',\n",
       " 'B_nt',\n",
       " 'I_nt',\n",
       " 'B_nr',\n",
       " 'I_nr',\n",
       " 'I_w',\n",
       " 'X',\n",
       " 'B_nz',\n",
       " 'I_nz',\n",
       " 'B_n',\n",
       " 'I_n',\n",
       " 'B_v',\n",
       " 'I_v',\n",
       " 'B_p',\n",
       " 'I_m',\n",
       " 'I_p',\n",
       " 'B_r',\n",
       " 'I_r',\n",
       " 'B_vn',\n",
       " 'I_vn',\n",
       " 'B_vd',\n",
       " 'I_vd',\n",
       " 'B_a',\n",
       " 'I_a',\n",
       " 'B_t',\n",
       " 'I_t',\n",
       " 'B_ti',\n",
       " 'I_ti',\n",
       " 'B_u',\n",
       " 'B_c',\n",
       " 'B_d',\n",
       " 'I_d',\n",
       " 'B_ns',\n",
       " 'I_ns',\n",
       " 'I_c',\n",
       " 'B_f',\n",
       " 'B_ad',\n",
       " 'I_ad',\n",
       " 'I_f',\n",
       " 'B_xc',\n",
       " 'B_s',\n",
       " 'I_s',\n",
       " 'B_an',\n",
       " 'I_an',\n",
       " 'B_nw',\n",
       " 'I_nw',\n",
       " 'I_u',\n",
       " 'B_xx',\n",
       " 'I_xx',\n",
       " 'I_xc',\n",
       " 'B_q',\n",
       " 'I_q']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160181"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnCRF\n",
    "model = BertBiLSTMAttnCRF.create(len(data.label2idx), bert_config_file, init_checkpoint_pt, enc_hidden_dim=256, use_cuda=False)\n",
    "model.get_n_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NerLearner\n",
    "num_epochs = 10\n",
    "learner = NerLearner(model, data,\n",
    "                     best_model_path=init_checkpoint_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-23 17:51:53,880 INFO: Resuming train... Current epoch 0.\n",
      "train loss: 752.8927001953125:   0%|          | 6/9748 [02:37<71:24:21, 26.39s/it]"
     ]
    }
   ],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6]",
   "language": "python",
   "name": "conda-env-py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
