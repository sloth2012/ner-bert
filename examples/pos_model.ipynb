{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath('../bailian_nlp/')\n",
    "\n",
    "data_path = os.path.join(root_dir, 'datadrive/bailian/pos')\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(data_path, 'train.csv')\n",
    "valid_path = os.path.join(data_path, 'valid.csv')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'datadrive/models/chinese_L-12_H-768_A-12/')\n",
    "init_checkpoint_pt = os.path.join(model_dir, 'bert_model.bin')\n",
    "bert_config_file = os.path.join(model_dir, 'bert_config.json')\n",
    "vocab_file = os.path.join(model_dir, 'vocab.txt')\n",
    "model_pt = os.path.join(model_dir, 'pos.bin')\n",
    "config_file = os.path.join(model_dir, 'pos.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 21700 0.008986175115207374\n",
      "274 31200 0.008782051282051282\n",
      "276 31700 0.008706624605678233\n",
      "307 36100 0.00850415512465374\n",
      "327 36600 0.008934426229508196\n",
      "356 37500 0.009493333333333333\n",
      "435 46200 0.009415584415584415\n",
      "624 67800 0.009203539823008849\n",
      "724 76800 0.009427083333333334\n",
      "914 98800 0.009251012145748989\n",
      "1091 120300 0.009068994181213633\n",
      "1204 134500 0.008951672862453531\n",
      "1397 156900 0.008903760356915232\n",
      "1415 158700 0.008916194076874606\n",
      "1725 203000 0.008497536945812808\n",
      "2048 416200 0.004920711196540125\n",
      "2054 793378 0.002588929866973876\n"
     ]
    }
   ],
   "source": [
    "# 初始化构造数据\n",
    "from bailian_nlp.preprocessing.build_data import build_pos_fake_data, build_pos_train_and_valid_data\n",
    "# build_pos_fake_data()\n",
    "build_pos_train_and_valid_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常训练\n",
    "\n",
    "# from bailian_nlp.modules import BertData\n",
    "\n",
    "# data = BertData.create(\n",
    "#     train_path,\n",
    "#     valid_path, \n",
    "#     vocab_file,\n",
    "#     data_type=\"bert_uncased\",\n",
    "#     max_seq_len=128,\n",
    "#     batch_size=128\n",
    "    \n",
    "# )\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from bailian_nlp.modules.models import bert_models\n",
    "reload(bert_models)\n",
    "\n",
    "model = bert_models.BertBiLSTMAttnCRF.create(\n",
    "    len(data.label2idx),\n",
    "    bert_config_file, \n",
    "    init_checkpoint_pt,\n",
    "    enc_hidden_dim=256\n",
    ")\n",
    "\n",
    "\n",
    "from bailian_nlp.modules.train import train\n",
    "reload(train)\n",
    "num_epochs = 15\n",
    "learner = train.NerLearner(model, data,\n",
    "                     best_model_path=model_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Resuming train... Current epoch 16.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30912fbe2e8494fbd276ad5ebacb1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6177), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bailian_nlp.released.pos:load default user_dict in /home/liuxiang/Projects/pos-bert/bailian_nlp/datadrive/dict/user_dict.txt\n",
      "INFO:bailian_nlp.released.dictionary:本次加载词条数：3\n",
      "INFO:bailian_nlp.released.dictionary:当前总词条数: 3\n",
      "INFO:root:Loading pretrained bert model!\n",
      "INFO:root:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:bailian_nlp.released.pos:found pos model file in /home/liuxiang/Projects/pos-bert/bailian_nlp/datadrive/models/chinese_L-12_H-768_A-12/pos.bin\n",
      "INFO:bailian_nlp.released.pos:pos model loads success!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfa5efe835a407888a7751e8e18dbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='bert data', max=786980, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:bailian_nlp.web.utils.common:get_data cost 82.997559s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3396c14e63a94ffa8756e42e2b1be786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='bert data', max=2606, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:bailian_nlp.web.utils.common:get_data cost 0.203217s\n",
      "INFO:root:Loading pretrained bert model!\n",
      "INFO:root:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bailian_nlp.released.pos:found pos model file in /home/liuxiang/Projects/pos-bert/bailian_nlp/datadrive/models/chinese_L-12_H-768_A-12/pos.bin\n",
      "INFO:bailian_nlp.released.pos:pos model loads success!\n",
      "INFO:root:Resuming train... Current epoch 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cba8210b0f4ed8a4f5fd310178683e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6149), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "epoch 1, average train epoch loss=1.9717\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b64e0c61a524c5a914dac34055c5240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:on epoch 0 by max_f1: 0.951\n",
      "INFO:root:Saving new best model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         S_r      0.993     0.983     0.988       414\n",
      "         I_m      0.950     0.975     0.962       589\n",
      "        E_an      0.760     0.745     0.752        51\n",
      "        B_xc      0.714     0.714     0.714        14\n",
      "         E_c      0.979     0.960     0.969       247\n",
      "        I_vn      0.916     0.826     0.869       172\n",
      "         I_d      0.972     0.921     0.946        76\n",
      "         S_f      0.980     0.974     0.977       497\n",
      "        I_nw      0.839     0.833     0.836       162\n",
      "        S_ad      0.944     0.708     0.810        24\n",
      "        S_ns      0.667     1.000     0.800         2\n",
      "        B_nt      0.958     0.976     0.967      4949\n",
      "        E_nw      0.909     0.820     0.862        61\n",
      "         S_c      0.975     0.979     0.977       845\n",
      "        I_xc      0.600     0.600     0.600         5\n",
      "         S_q      0.929     0.890     0.909        73\n",
      "         I_s      1.000     0.750     0.857         8\n",
      "         S_p      0.964     0.974     0.969      1629\n",
      "        E_nr      0.949     0.932     0.941      3765\n",
      "       [CLS]      1.000     1.000     1.000      2606\n",
      "         I_f      1.000     1.000     1.000         2\n",
      "         E_q      0.000     0.000     0.000         0\n",
      "         E_t      0.988     0.984     0.986      1194\n",
      "        B_nz      0.826     0.708     0.762      1110\n",
      "        E_ns      0.942     0.782     0.855      1736\n",
      "        B_an      0.760     0.745     0.752        51\n",
      "        B_xx      0.000     0.000     0.000        36\n",
      "         E_a      0.944     0.928     0.936      1113\n",
      "         B_p      0.957     0.993     0.974       267\n",
      "        E_ti      0.980     0.950     0.965      2724\n",
      "        S_nr      0.000     0.000     0.000         0\n",
      "       <pad>      0.000     0.000     0.000         0\n",
      "         B_s      0.949     0.933     0.941       179\n",
      "         S_d      0.975     0.961     0.968       861\n",
      "        I_an      1.000     1.000     1.000         2\n",
      "         I_l      0.000     0.000     0.000         0\n",
      "         B_i      0.000     0.000     0.000         0\n",
      "         B_v      0.961     0.950     0.956      5462\n",
      "        E_nt      0.953     0.944     0.949      4880\n",
      "         B_c      0.979     0.960     0.969       247\n",
      "         I_u      0.000     0.000     0.000         0\n",
      "        E_vd      0.836     0.848     0.842        66\n",
      "         I_r      0.857     1.000     0.923        24\n",
      "        B_ad      0.948     0.926     0.937       337\n",
      "        E_nz      0.816     0.684     0.744      1092\n",
      "        E_xc      0.714     0.714     0.714        14\n",
      "        S_nz      0.855     0.876     0.865       169\n",
      "         S_n      0.896     0.838     0.866       809\n",
      "         I_p      0.000     0.000     0.000         0\n",
      "        E_vn      0.911     0.924     0.917      2644\n",
      "         I_i      0.000     0.000     0.000         0\n",
      "         E_l      0.000     0.000     0.000         0\n",
      "         E_v      0.962     0.951     0.956      5428\n",
      "        I_vd      0.000     0.000     0.000         0\n",
      "         B_r      0.964     0.988     0.976       675\n",
      "        I_xx      0.000     0.000     0.000        57\n",
      "         E_d      0.955     0.951     0.953       740\n",
      "        E_ad      0.948     0.926     0.937       337\n",
      "        S_xx      0.000     0.000     0.000         0\n",
      "        S_nt      0.839     0.867     0.852        30\n",
      "         I_q      0.000     0.000     0.000         0\n",
      "         B_l      0.000     0.000     0.000         0\n",
      "         B_w      1.000     1.000     1.000        11\n",
      "        I_nr      0.905     0.966     0.935      2853\n",
      "        B_vn      0.908     0.922     0.915      2666\n",
      "        S_ti      0.983     0.976     0.980       297\n",
      "         I_n      0.874     0.914     0.893      1536\n",
      "         E_r      0.968     0.990     0.979       670\n",
      "        I_ti      0.951     0.996     0.973      3710\n",
      "        B_vd      0.836     0.848     0.842        66\n",
      "         I_w      1.000     1.000     1.000         1\n",
      "        I_xu      1.000     1.000     1.000        13\n",
      "         B_f      0.935     0.940     0.937       199\n",
      "        B_nr      0.952     0.982     0.967      3786\n",
      "         I_a      0.889     0.784     0.833       153\n",
      "         E_m      0.957     0.964     0.961      1051\n",
      "         S_j      0.000     0.000     0.000         0\n",
      "         B_q      0.000     0.000     0.000         0\n",
      "        I_ad      1.000     0.750     0.857         8\n",
      "         E_s      0.955     0.939     0.946       179\n",
      "         E_n      0.954     0.952     0.953      8685\n",
      "         S_a      0.915     0.897     0.906       458\n",
      "        B_ti      0.983     0.996     0.989      2748\n",
      "         I_j      0.000     0.000     0.000         0\n",
      "         B_t      0.988     0.983     0.986      1203\n",
      "         S_v      0.954     0.926     0.940      1945\n",
      "        S_vd      1.000     0.333     0.500         3\n",
      "         S_s      0.000     0.000     0.000         0\n",
      "         B_d      0.957     0.953     0.955       742\n",
      "         B_j      0.000     0.000     0.000         0\n",
      "         B_n      0.951     0.952     0.952      8749\n",
      "         S_m      0.963     0.894     0.928       265\n",
      "         E_j      0.000     0.000     0.000         0\n",
      "        E_xx      0.000     0.000     0.000        36\n",
      "        I_nz      0.773     0.691     0.730      1635\n",
      "         E_u      1.000     1.000     1.000         6\n",
      "         I_v      0.887     0.880     0.883       366\n",
      "         S_w      0.999     0.998     0.999      9547\n",
      "        S_an      0.900     0.529     0.667        17\n",
      "        S_vn      0.836     0.807     0.821        57\n",
      "        S_xc      0.917     0.827     0.870       133\n",
      "        B_nw      0.929     0.852     0.889        61\n",
      "         E_f      0.935     0.940     0.937       199\n",
      "         E_i      0.000     0.000     0.000         0\n",
      "        I_ns      0.869     0.918     0.893      2120\n",
      "         S_t      0.900     0.643     0.750        14\n",
      "        I_nt      0.961     0.989     0.975     21300\n",
      "        B_xu      1.000     1.000     1.000         1\n",
      "         I_c      1.000     1.000     1.000         6\n",
      "         B_m      0.958     0.969     0.963      1058\n",
      "         S_u      0.996     0.996     0.996      2973\n",
      "        E_xu      1.000     1.000     1.000         1\n",
      "         E_p      0.957     0.992     0.974       266\n",
      "         B_a      0.945     0.928     0.937      1118\n",
      "         I_t      0.974     0.996     0.985      1119\n",
      "        B_ns      0.945     0.887     0.915      1738\n",
      "         E_w      1.000     1.000     1.000        11\n",
      "        S_nw      0.000     0.000     0.000         0\n",
      "         B_u      1.000     1.000     1.000         6\n",
      "\n",
      "   micro avg      0.952     0.952     0.952    134260\n",
      "   macro avg      0.741     0.719     0.727    134260\n",
      "weighted avg      0.951     0.952     0.951    134260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 恢复训练\n",
    "\n",
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n",
    "tagger.init_env(for_train=True)\n",
    "\n",
    "data = tagger.learner.data\n",
    "learner = tagger.learner\n",
    "num_epochs = 1\n",
    "# learner.load_model()\n",
    "learner.t_total = num_epochs * len(data.train_dl)\n",
    "learner.sup_labels = list(set(data.id2label[1:]) | set(learner.sup_labels))\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import bert_data\n",
    "reload(bert_data)\n",
    "dl = bert_data.get_bert_data_loader_for_predict(valid_path, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load_model()\n",
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bailian_nlp.released.pos:load default user_dict in /home/liuxiang/Projects/pos-bert/bailian_nlp/datadrive/dict/user_dict.txt\n",
      "INFO:bailian_nlp.released.dictionary:本次加载词条数：3\n",
      "INFO:bailian_nlp.released.dictionary:当前总词条数: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "from_config() got an unexpected keyword argument 'bert_config_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ccb7e585b235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPosTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/released/pos.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mhas_load_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/released/pos.py\u001b[0m in \u001b[0;36minit_env\u001b[0;34m(self, for_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_POS_MODEL_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNerLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfor_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/modules/train/train.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, for_train)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/modules/utils/utils.py\u001b[0m in \u001b[0;36mrecover_model_from_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/modules/models/bert_models.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mencoder_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdecoder_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/modules/layers/encoders.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BertEmbedder\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEmbedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"form_config is implemented only for BertEmbedder now :(\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: from_config() got an unexpected keyword argument 'bert_config_file'"
     ]
    }
   ],
   "source": [
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NerLearner' object has no attribute 'cut'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a5777543d973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# text = '2012-11-8 的客户包括：宝洁 、杜邦、强生、百事可 乐、3M 、三菱、吉列、通用医疗系统、美国 运通、雅芳、纽约银 行、百时美—施贵 宝、礼来、迪斯尼、纳贝斯克、纽约'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# text = '网：tmall.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0med\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0med\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NerLearner' object has no attribute 'cut'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "text = '近日，编程猫（深圳点猫科技有限公司）正式对外宣布完成B轮1.2亿元融资。本轮融资由高瓴资本领投，清流资本、清晗基金跟投，天使轮投资者猎豹移动继续跟投。'\n",
    "# text = '未来编程教育产业将蓬勃发展，编程猫作为提供工具与内容的企业，有望长期处于行业领跑者地位。'\n",
    "# text = '美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司始创于2004年,是中国健康体检和医疗服务集团,总部位于上海,深耕布局北京、深圳、沈阳、广州、成都、武汉、...'\n",
    "# text = '百炼智能百炼智能'\n",
    "# text = '高越君冯是聪'\n",
    "# text = '周光明确否认CEO佟显侨和衡量推动发出公司公告'\n",
    "# text = '周光明确否认CEO佟显侨和CTO衡量说的罪名'\n",
    "# text = '董事'\n",
    "text = '一言不合'\n",
    "# text = '客户包括雀巢、洲际酒店、瑞士航空、德意志银行、红牛、瑞士联合银行等世界知名公司。'\n",
    "# text = '药方越是多的，越表明病是难的于治疗'\n",
    "# text = '2012-11-8 的客户包括：宝洁 、杜邦、强生、百事可 乐、3M 、三菱、吉列、通用医疗系统、美国 运通、雅芳、纽约银 行、百时美—施贵 宝、礼来、迪斯尼、纳贝斯克、纽约'\n",
    "# text = '网：tmall.com'\n",
    "res = learner.cut(text)\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'á'\n",
    "acc = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1',\n",
       "  '.',\n",
       "  '未',\n",
       "  'a',\n",
       "  '来',\n",
       "  '伙',\n",
       "  '伴',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '费',\n",
       "  '旭',\n",
       "  '锋',\n",
       "  '：',\n",
       "  '教',\n",
       "  '育',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '市',\n",
       "  '场',\n",
       "  '预',\n",
       "  '计',\n",
       "  '在',\n",
       "  '2025',\n",
       "  '年',\n",
       "  '会',\n",
       "  '达',\n",
       "  '到',\n",
       "  '3000',\n",
       "  '亿'],\n",
       " [(-2, (1, 2)),\n",
       "  (-2, (3, 4)),\n",
       "  (-2, (4, 5)),\n",
       "  (1, (0, 1)),\n",
       "  (1, (1, 2)),\n",
       "  (1, (5, 6)),\n",
       "  (-2, (7, 8)),\n",
       "  (1, (6, 7)),\n",
       "  (1, (8, 9)),\n",
       "  (-2, (9, 10)),\n",
       "  (-2, (10, 11)),\n",
       "  (1, (11, 12)),\n",
       "  (1, (12, 13)),\n",
       "  (1, (13, 14)),\n",
       "  (1, (14, 15)),\n",
       "  (1, (15, 16)),\n",
       "  (1, (16, 17)),\n",
       "  (1, (17, 18)),\n",
       "  (1, (18, 19)),\n",
       "  (1, (19, 20)),\n",
       "  (0, (20, 21)),\n",
       "  (1, (21, 22)),\n",
       "  (1, (22, 23)),\n",
       "  (1, (23, 24)),\n",
       "  (1, (24, 25)),\n",
       "  (1, (25, 26)),\n",
       "  (1, (26, 27)),\n",
       "  (1, (27, 28)),\n",
       "  (1, (28, 29)),\n",
       "  (1, (29, 30)),\n",
       "  (1, (30, 31)),\n",
       "  (1, (31, 35)),\n",
       "  (1, (35, 36)),\n",
       "  (1, (36, 37)),\n",
       "  (1, (37, 38)),\n",
       "  (1, (38, 39)),\n",
       "  (1, (39, 43)),\n",
       "  (1, (43, 44))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'未'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = '1́.́́未á来́́伙伴机器人费旭锋： 教育机器人市场预计在2025年会达到3000亿'\n",
    "ww[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 S_m\n",
      ". S_w\n",
      "未 B_nt\n",
      "a I_nt\n",
      "来 I_nt\n",
      "伙 I_nt\n",
      "伴 I_nt\n",
      "机 I_nt\n",
      "器 I_nt\n",
      "人 E_nt\n",
      "费 B_nr\n",
      "旭 I_nr\n",
      "锋 E_nr\n",
      "： S_w\n",
      "教 B_nz\n",
      "育 I_nz\n",
      "机 I_nz\n",
      "器 I_nz\n",
      "人 E_nz\n",
      "市 B_n\n",
      "场 E_n\n",
      "预 B_v\n",
      "计 E_v\n",
      "在 S_p\n",
      "2025 S_m\n",
      "年 B_n\n",
      "会 E_n\n",
      "达 B_v\n",
      "到 E_v\n",
      "3000 B_m\n",
      "亿 E_m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1',\n",
       "  '.',\n",
       "  '未',\n",
       "  'a',\n",
       "  '来',\n",
       "  '伙',\n",
       "  '伴',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '费',\n",
       "  '旭',\n",
       "  '锋',\n",
       "  '：',\n",
       "  '教',\n",
       "  '育',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '市',\n",
       "  '场',\n",
       "  '预',\n",
       "  '计',\n",
       "  '在',\n",
       "  '2025',\n",
       "  '年',\n",
       "  '会',\n",
       "  '达',\n",
       "  '到',\n",
       "  '3000',\n",
       "  '亿'],\n",
       " ['S_m',\n",
       "  'S_w',\n",
       "  'B_nt',\n",
       "  'I_nt',\n",
       "  'I_nt',\n",
       "  'I_nt',\n",
       "  'I_nt',\n",
       "  'I_nt',\n",
       "  'I_nt',\n",
       "  'E_nt',\n",
       "  'B_nr',\n",
       "  'I_nr',\n",
       "  'E_nr',\n",
       "  'S_w',\n",
       "  'B_nz',\n",
       "  'I_nz',\n",
       "  'I_nz',\n",
       "  'I_nz',\n",
       "  'E_nz',\n",
       "  'B_n',\n",
       "  'E_n',\n",
       "  'B_v',\n",
       "  'E_v',\n",
       "  'S_p',\n",
       "  'S_m',\n",
       "  'B_n',\n",
       "  'E_n',\n",
       "  'B_v',\n",
       "  'E_v',\n",
       "  'B_m',\n",
       "  'E_m'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bailian_nlp.modules.data.tokenization import BailianTokenizer\n",
    "tokenizer = BailianTokenizer()\n",
    "text = f'1{acc}/m ./w {acc}{acc}未á来{acc}{acc}伙伴机器人/nt 费旭锋/nr ：/w  /w 教育机器人/nz 市场/n 预计/v 在/p 2025/m 年会/n 达到/v 3000亿/m'\n",
    "tokenizer.tokenize_with_pos_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
