{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath('../bailian_nlp/')\n",
    "\n",
    "data_path = os.path.join(root_dir, 'datadrive/bailian/pos')\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(data_path, 'train.csv')\n",
    "valid_path = os.path.join(data_path, 'valid.csv')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'datadrive/models/chinese_L-12_H-768_A-12/')\n",
    "init_checkpoint_pt = os.path.join(model_dir, 'bert_model.bin')\n",
    "bert_config_file = os.path.join(model_dir, 'bert_config.json')\n",
    "vocab_file = os.path.join(model_dir, 'vocab.txt')\n",
    "model_pt = os.path.join(model_dir, 'pos.bin')\n",
    "config_file = os.path.join(model_dir, 'pos.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化构造数据\n",
    "from bailian_nlp.preprocessing.build_data import build_pos_fake_data, build_pos_train_and_valid_data\n",
    "# build_pos_fake_data()\n",
    "build_pos_train_and_valid_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常训练\n",
    "\n",
    "from bailian_nlp.modules import BertData\n",
    "\n",
    "data = BertData.create(\n",
    "    train_path,\n",
    "    valid_path, \n",
    "    vocab_file,\n",
    "    data_type=\"bert_uncased\",\n",
    "    max_seq_len=128,\n",
    "    batch_size=128\n",
    "    \n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from bailian_nlp.modules.models import bert_models\n",
    "reload(bert_models)\n",
    "\n",
    "model = bert_models.BertBiLSTMAttnCRF.create(\n",
    "    len(data.label2idx),\n",
    "    enc_hidden_dim=256\n",
    ")\n",
    "\n",
    "\n",
    "from bailian_nlp.modules.train import train\n",
    "reload(train)\n",
    "num_epochs = 10\n",
    "learner = train.NerLearner(model, data,\n",
    "                     best_model_path=model_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from bailian_nlp.modules.models import bert_models\n",
    "reload(bert_models)\n",
    "\n",
    "model = bert_models.BertBiLSTMAttnCRF.create(\n",
    "    len(data.label2idx),\n",
    "    enc_hidden_dim=256\n",
    ")\n",
    "model.get_n_trainable_params()\n",
    "\n",
    "\n",
    "from bailian_nlp.modules.train import train\n",
    "reload(train)\n",
    "num_epochs = 2\n",
    "learner = train.NerLearner(model, data,\n",
    "                     best_model_path=model_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复训练\n",
    "\n",
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n",
    "tagger.init_env(for_train=True)\n",
    "\n",
    "data = tagger.learner.data\n",
    "learner = tagger.learner\n",
    "num_epochs = 1\n",
    "learner.load_model()\n",
    "learner.t_total = num_epochs * len(data.train_dl)\n",
    "learner.sup_labels = list(set(data.id2label[1:]) | set(learner.sup_labels))\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import bert_data\n",
    "reload(bert_data)\n",
    "dl = bert_data.get_bert_data_loader_for_predict(valid_path, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load_model()\n",
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "text = '近日，编程猫（深圳点猫科技有限公司）正式对外宣布完成B轮1.2亿元融资。本轮融资由高瓴资本领投，清流资本、清晗基金跟投，天使轮投资者猎豹移动继续跟投。'\n",
    "# text = '未来编程教育产业将蓬勃发展，编程猫作为提供工具与内容的企业，有望长期处于行业领跑者地位。'\n",
    "# text = '美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司始创于2004年,是中国健康体检和医疗服务集团,总部位于上海,深耕布局北京、深圳、沈阳、广州、成都、武汉、...'\n",
    "# text = '百炼智能百炼智能'\n",
    "# text = '高越君冯是聪'\n",
    "text = '周光明确否认CEO佟显侨和衡量推动发出公司公告'\n",
    "text = '周光明确否认CEO佟显侨和CTO衡量说的罪名'\n",
    "text = '董事'\n",
    "# text = '一言九鼎'\n",
    "# text = '客户包括雀巢、洲际酒店、瑞士航空、德意志银行、红牛、瑞士联合银行等世界知名公司。'\n",
    "# text = '药方越是多的，越表明病是难的于治疗'\n",
    "text = '2012-11-8 的客户包括：宝洁 、杜邦、强生、百事可 乐、3M 、三菱、吉列、通用医疗系统、美国 运通、雅芳、纽约银 行、百时美—施贵 宝、礼来、迪斯尼、纳贝斯克、纽约'\n",
    "res = tagger.cut(text)\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'á'\n",
    "acc = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1',\n",
       "  '.',\n",
       "  '未',\n",
       "  'a',\n",
       "  '来',\n",
       "  '伙',\n",
       "  '伴',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '费',\n",
       "  '旭',\n",
       "  '锋',\n",
       "  '：',\n",
       "  '教',\n",
       "  '育',\n",
       "  '机',\n",
       "  '器',\n",
       "  '人',\n",
       "  '市',\n",
       "  '场',\n",
       "  '预',\n",
       "  '计',\n",
       "  '在',\n",
       "  '2025',\n",
       "  '年',\n",
       "  '会',\n",
       "  '达',\n",
       "  '到',\n",
       "  '3000',\n",
       "  '亿'],\n",
       " [(-2, (1, 2)),\n",
       "  (-2, (3, 4)),\n",
       "  (-2, (4, 5)),\n",
       "  (1, (0, 1)),\n",
       "  (1, (1, 2)),\n",
       "  (1, (5, 6)),\n",
       "  (-2, (7, 8)),\n",
       "  (1, (6, 7)),\n",
       "  (1, (8, 9)),\n",
       "  (-2, (9, 10)),\n",
       "  (-2, (10, 11)),\n",
       "  (1, (11, 12)),\n",
       "  (1, (12, 13)),\n",
       "  (1, (13, 14)),\n",
       "  (1, (14, 15)),\n",
       "  (1, (15, 16)),\n",
       "  (1, (16, 17)),\n",
       "  (1, (17, 18)),\n",
       "  (1, (18, 19)),\n",
       "  (1, (19, 20)),\n",
       "  (0, (20, 21)),\n",
       "  (1, (21, 22)),\n",
       "  (1, (22, 23)),\n",
       "  (1, (23, 24)),\n",
       "  (1, (24, 25)),\n",
       "  (1, (25, 26)),\n",
       "  (1, (26, 27)),\n",
       "  (1, (27, 28)),\n",
       "  (1, (28, 29)),\n",
       "  (1, (29, 30)),\n",
       "  (1, (30, 31)),\n",
       "  (1, (31, 35)),\n",
       "  (1, (35, 36)),\n",
       "  (1, (36, 37)),\n",
       "  (1, (37, 38)),\n",
       "  (1, (38, 39)),\n",
       "  (1, (39, 43)),\n",
       "  (1, (43, 44))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'未'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = '1́.́́未á来́́伙伴机器人费旭锋： 教育机器人市场预计在2025年会达到3000亿'\n",
    "ww[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-2, (1, 2)), (-2, (3, 4)), (-2, (4, 5)), (1, (0, 1)), (1, (1, 2)), (1, (5, 6)), (-2, (7, 8)), (1, (6, 7)), (1, (8, 9)), (-2, (9, 10)), (-2, (10, 11)), (1, (11, 12)), (1, (12, 13)), (1, (13, 14)), (1, (14, 15)), (1, (15, 16)), (1, (16, 17)), (1, (17, 18)), (1, (18, 19)), (1, (19, 20)), (0, (20, 21)), (1, (21, 22)), (1, (22, 23)), (1, (23, 24)), (1, (24, 25)), (1, (25, 26)), (1, (26, 27)), (1, (27, 28)), (1, (28, 29)), (1, (29, 30)), (1, (30, 31)), (1, (31, 35)), (1, (35, 36)), (1, (36, 37)), (1, (37, 38)), (1, (38, 39)), (1, (39, 43)), (1, (43, 44))]\n",
      "1́.́́未á来́́伙伴机器人费旭锋： 教育机器人市场预计在2025年会达到3000亿\n",
      "99999 1 0 1\n",
      "ps 1 0 0 0\n",
      "wwwwww 1 [('m', 0)] 1 0\n",
      "99999 1 1 2\n",
      "eneeeeeee 1 2\n",
      "ps ́. 1 0 0\n",
      "wwwwww 2 [('m', 0), ('w', 1)] ́. 0\n",
      "99999 1 5 6\n",
      "ps  5 1 0\n",
      "wwwwww 3 []  0\n",
      "99999 1 6 7\n",
      "ps a 6 0 0\n",
      "wwwwww 4 [('nt', 2)] a 0\n",
      "99999 1 8 9\n",
      "ps 来 8 0 0\n",
      "wwwwww 5 [('nt', 2)] 来 0\n",
      "99999 1 11 12\n",
      "ps 伙 11 0 0\n",
      "wwwwww 6 [('nt', 2)] 伙 0\n",
      "99999 1 12 13\n",
      "ps 伴 12 0 0\n",
      "wwwwww 7 [('nt', 2)] 伴 0\n",
      "99999 1 13 14\n",
      "ps 机 13 0 0\n",
      "wwwwww 8 [('nt', 2)] 机 0\n",
      "99999 1 14 15\n",
      "ps 器 14 0 0\n",
      "wwwwww 9 [('nt', 2)] 器 0\n",
      "99999 1 15 16\n",
      "ps 人 15 0 0\n",
      "wwwwww 10 [('nt', 2)] 人 0\n",
      "99999 1 16 17\n",
      "ps 费 16 0 0\n",
      "wwwwww 11 [('nr', 3)] 费 0\n",
      "99999 1 17 18\n",
      "ps 旭 17 0 0\n",
      "wwwwww 12 [('nr', 3)] 旭 0\n",
      "99999 1 18 19\n",
      "ps 锋 18 0 0\n",
      "wwwwww 13 [('nr', 3)] 锋 0\n",
      "99999 1 19 20\n",
      "ps ： 19 0 0\n",
      "wwwwww 14 [('w', 4)] ： 0\n",
      "99999 1 21 22\n",
      "ps 教 21 0 0\n",
      "wwwwww 15 [('nz', 6)] 教 0\n",
      "99999 1 22 23\n",
      "ps 育 22 0 0\n",
      "wwwwww 16 [('nz', 6)] 育 0\n",
      "99999 1 23 24\n",
      "ps 机 23 0 0\n",
      "wwwwww 17 [('nz', 6)] 机 0\n",
      "99999 1 24 25\n",
      "ps 器 24 0 0\n",
      "wwwwww 18 [('nz', 6)] 器 0\n",
      "99999 1 25 26\n",
      "ps 人 25 0 0\n",
      "wwwwww 19 [('nz', 6)] 人 0\n",
      "99999 1 26 27\n",
      "ps 市 26 0 0\n",
      "wwwwww 20 [('n', 7)] 市 0\n",
      "99999 1 27 28\n",
      "ps 场 27 0 0\n",
      "wwwwww 21 [('n', 7)] 场 0\n",
      "99999 1 28 29\n",
      "ps 预 28 0 0\n",
      "wwwwww 22 [('v', 8)] 预 0\n",
      "99999 1 29 30\n",
      "ps 计 29 0 0\n",
      "wwwwww 23 [('v', 8)] 计 0\n",
      "99999 1 30 31\n",
      "ps 在 30 0 0\n",
      "wwwwww 24 [('p', 9)] 在 0\n",
      "99999 1 31 35\n",
      "ps 2025 31 0 0\n",
      "wwwwww 25 [('m', 10), ('m', 10), ('m', 10), ('m', 10)] 2025 0\n",
      "99999 1 35 36\n",
      "ps 年 35 0 0\n",
      "wwwwww 26 [('n', 11)] 年 0\n",
      "99999 1 36 37\n",
      "ps 会 36 0 0\n",
      "wwwwww 27 [('n', 11)] 会 0\n",
      "99999 1 37 38\n",
      "ps 达 37 0 0\n",
      "wwwwww 28 [('v', 12)] 达 0\n",
      "99999 1 38 39\n",
      "ps 到 38 0 0\n",
      "wwwwww 29 [('v', 12)] 到 0\n",
      "99999 1 39 43\n",
      "ps 3000 39 0 0\n",
      "wwwwww 30 [('m', 13), ('m', 13), ('m', 13), ('m', 13)] 3000 0\n",
      "99999 1 43 44\n",
      "ps 亿 43 0 0\n",
      "wwwwww 31 [('m', 13)] 亿 0\n",
      "1 [('m', 0)]\n",
      ". [('m', 0), ('w', 1)]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "原有分词与现有tokenizer有冲突",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-b5989633d18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBailianTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'1{acc}/m ./w {acc}{acc}未á来{acc}{acc}伙伴机器人/nt 费旭锋/nr ：/w  /w 教育机器人/nz 市场/n 预计/v 在/p 2025/m 年会/n 达到/v 3000亿/m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_with_pos_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/pos-bert/bailian_nlp/modules/data/tokenization.py\u001b[0m in \u001b[0;36mtokenize_with_pos_text\u001b[0;34m(self, pos_sent)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_label\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'原有分词与现有tokenizer有冲突'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlast_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: 原有分词与现有tokenizer有冲突"
     ]
    }
   ],
   "source": [
    "from bailian_nlp.modules.data.tokenization import BailianTokenizer\n",
    "tokenizer = BailianTokenizer()\n",
    "text = f'1{acc}/m ./w {acc}{acc}未á来{acc}{acc}伙伴机器人/nt 费旭锋/nr ：/w  /w 教育机器人/nz 市场/n 预计/v 在/p 2025/m 年会/n 达到/v 3000亿/m'\n",
    "tokenizer.tokenize_with_pos_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6]",
   "language": "python",
   "name": "conda-env-py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
