{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath('../bailian_nlp/')\n",
    "\n",
    "data_path = os.path.join(root_dir, 'datadrive/bailian/pos')\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(data_path, 'train.csv')\n",
    "valid_path = os.path.join(data_path, 'valid.csv')\n",
    "\n",
    "model_dir = os.path.join(root_dir, 'datadrive/models/chinese_L-12_H-768_A-12/')\n",
    "init_checkpoint_pt = os.path.join(model_dir, 'bert_model.bin')\n",
    "bert_config_file = os.path.join(model_dir, 'bert_config.json')\n",
    "vocab_file = os.path.join(model_dir, 'vocab.txt')\n",
    "model_pt = os.path.join(model_dir, 'pos.bin')\n",
    "config_file = os.path.join(model_dir, 'pos.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 165566 0.003201140330744235\n",
      "531 165711 0.0032043738798269274\n",
      "532 165712 0.003210389108815294\n",
      "533 165713 0.003216404265205506\n",
      "534 166055 0.003215801993315468\n",
      "535 166060 0.0032217270865952065\n",
      "536 166749 0.0032144120804322666\n",
      "537 167083 0.0032139714991950108\n",
      "538 167553 0.0032109243045484116\n",
      "539 167569 0.003216585406608621\n",
      "540 170842 0.0031608152562016367\n",
      "541 171156 0.0031608590993012224\n",
      "542 171191 0.0031660542902372203\n",
      "543 171338 0.0031691743804643452\n",
      "544 171339 0.0031749922667927326\n",
      "545 171340 0.0031808100852106923\n",
      "546 171375 0.003185995623632385\n",
      "547 171376 0.0031918121557277567\n",
      "548 171377 0.0031976286199431663\n",
      "549 171400 0.0032030338389731623\n",
      "550 172290 0.003192292065703175\n",
      "551 172772 0.003189174171740791\n",
      "552 172791 0.0031946108304251957\n",
      "553 174101 0.003176317195191297\n",
      "554 174106 0.003181969604723559\n",
      "555 174468 0.0031810991127312746\n",
      "556 174485 0.0031865203312605667\n",
      "557 174486 0.003192233187762915\n",
      "558 174487 0.0031979459787835197\n",
      "559 174491 0.0032036036242556925\n",
      "560 174847 0.0032028001624277223\n",
      "561 176174 0.003184351833982313\n",
      "562 176334 0.00318713350800186\n",
      "563 176370 0.0031921528604637976\n",
      "564 176778 0.0031904422496011947\n",
      "565 176779 0.0031960809824696373\n",
      "566 176780 0.0032017196515442925\n",
      "567 176847 0.003206161258036608\n",
      "568 176952 0.0032099100320991\n",
      "569 178149 0.0031939556214180265\n",
      "570 179266 0.0031796325014224673\n",
      "571 179422 0.0031824413951466375\n",
      "572 180410 0.0031705559558782774\n",
      "573 180800 0.0031692477876106196\n",
      "574 181053 0.0031703423859311916\n",
      "575 181194 0.0031733942625031732\n",
      "576 181979 0.003165200380263657\n",
      "577 183142 0.003150560767055072\n",
      "578 183195 0.0031551079450858376\n",
      "579 183197 0.0031605321047833753\n",
      "580 183286 0.0031644533679604553\n",
      "581 184938 0.00314159339886881\n",
      "582 184939 0.0031469835999978373\n",
      "583 187459 0.0031100133895945246\n",
      "584 187460 0.0031153312706710765\n",
      "585 188101 0.0031100313129648434\n",
      "586 188102 0.0031153310437953877\n",
      "587 188103 0.0031206307182766887\n",
      "588 189787 0.0030982100986895835\n",
      "589 189788 0.0031034628111366366\n",
      "590 190057 0.0031043318583372356\n",
      "591 191386 0.0030880001672013626\n",
      "592 191565 0.00309033487328061\n",
      "593 191606 0.0030948926442804503\n",
      "594 192855 0.0030800342226024735\n",
      "595 193156 0.003080411687962062\n",
      "596 193485 0.0030803421453859474\n",
      "597 194069 0.003076225466200166\n",
      "598 194070 0.003081362395012109\n",
      "599 194071 0.003086499270885398\n",
      "600 194072 0.00309163609382085\n",
      "601 194073 0.0030967728638192846\n",
      "602 194771 0.0030908092067094177\n",
      "603 195358 0.0030866409361275196\n",
      "604 196351 0.003076123880194142\n",
      "605 196589 0.0030774865328171974\n",
      "606 197701 0.003065234874886824\n",
      "607 198137 0.003063536845717862\n",
      "608 198985 0.00305550669648466\n",
      "609 199026 0.003059901721383136\n",
      "610 199027 0.0030649107909982063\n",
      "611 199048 0.0030696113500261243\n",
      "612 199081 0.003074125607164923\n",
      "613 199082 0.0030791332214866237\n",
      "614 199125 0.0030834902699309477\n",
      "615 199132 0.0030884036719362033\n",
      "616 199253 0.0030915469277752405\n",
      "617 199408 0.0030941587097809515\n",
      "618 199414 0.003099080305294513\n",
      "619 199416 0.003104063866490151\n",
      "620 199575 0.003106601528247526\n",
      "621 199579 0.0031115498123550074\n",
      "622 199897 0.0031116024752747664\n",
      "623 200648 0.0031049399944180853\n",
      "624 200819 0.0031072757059839957\n",
      "625 201123 0.003107551100570298\n",
      "626 201209 0.003111192839286513\n",
      "627 201215 0.0031160698755062994\n",
      "628 201337 0.003119148492328782\n",
      "629 201551 0.003120798209882362\n",
      "630 202091 0.003117407504540034\n",
      "631 202092 0.003122340320250183\n",
      "632 202273 0.0031244901692267383\n",
      "633 202351 0.0031282276835795228\n",
      "634 202367 0.003132921869672427\n",
      "635 203209 0.003124861595697041\n",
      "636 204486 0.0031102373756638595\n",
      "637 204999 0.003107332230888931\n",
      "638 205032 0.0031117093917047093\n",
      "639 205857 0.0031040965330302104\n",
      "640 205859 0.003108924069387299\n",
      "641 205870 0.0031136153883518725\n",
      "642 206733 0.0031054548620684653\n",
      "643 206910 0.003107631337296409\n",
      "644 207044 0.003110449952667066\n",
      "645 207114 0.0031142269474782004\n",
      "646 207301 0.003116241600378194\n",
      "647 209299 0.0030912713390890546\n",
      "648 209300 0.0030960344003822266\n",
      "649 209301 0.0031007974161614137\n",
      "650 209461 0.0031032029828941903\n",
      "651 209468 0.003107873278973399\n",
      "652 210251 0.0031010554052061583\n",
      "653 210978 0.003095109442690707\n",
      "654 211383 0.003093910106299939\n",
      "655 211483 0.003097175659509275\n",
      "656 211850 0.0030965305640783575\n",
      "657 213161 0.0030821773213674172\n",
      "658 213162 0.0030868541297229338\n",
      "659 213163 0.0030915308941983364\n",
      "660 213986 0.0030843139270793417\n",
      "661 214099 0.0030873567835440615\n",
      "662 215057 0.003078253672282232\n",
      "663 215058 0.0030828892670814387\n",
      "664 215823 0.0030765951728963085\n",
      "665 215824 0.0030812143227815256\n",
      "666 215825 0.003085833429862157\n",
      "667 215997 0.0030880058519331286\n",
      "668 216537 0.003084923130919889\n",
      "669 217017 0.003082707806300889\n",
      "670 217078 0.0030864481891301745\n",
      "671 217257 0.0030885080802920046\n",
      "672 217258 0.0030930966868884\n",
      "673 217476 0.0030945943460427817\n",
      "674 217481 0.0030991213025505678\n",
      "675 217540 0.003102877631699917\n",
      "676 221011 0.0030586712878544506\n",
      "677 221012 0.00306318208966029\n",
      "678 221013 0.0030676928506467947\n",
      "679 221623 0.0030637614327032846\n",
      "680 222013 0.0030628837050082655\n",
      "681 222113 0.0030660069424121956\n",
      "682 222114 0.003070495331226307\n",
      "683 222402 0.0030710155484213273\n",
      "684 222793 0.003070114411135\n",
      "685 222794 0.0030745890822912645\n",
      "686 222795 0.0030790637132790235\n",
      "687 222796 0.0030835383040988167\n",
      "688 222797 0.003088012854751186\n",
      "689 222798 0.0030924873652366717\n",
      "690 222799 0.0030969618355558147\n",
      "691 222800 0.003101436265709156\n",
      "692 222801 0.0031059106556972364\n",
      "693 222802 0.003110385005520597\n",
      "694 254427 0.0027276979251415925\n",
      "695 361352 0.0019233323739733003\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "not readable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ccb8ecc5069c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbailian_nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_pos_fake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_pos_train_and_valid_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# build_pos_fake_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbuild_pos_train_and_valid_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/pos-bert/bailian_nlp/preprocessing/build_data.py\u001b[0m in \u001b[0;36mbuild_pos_train_and_valid_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0merror_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not readable"
     ]
    }
   ],
   "source": [
    "# 初始化构造数据\n",
    "from bailian_nlp.preprocessing.build_data import build_pos_fake_data, build_pos_train_and_valid_data\n",
    "# build_pos_fake_data()\n",
    "build_pos_train_and_valid_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正常训练\n",
    "\n",
    "from bailian_nlp.modules import BertData\n",
    "\n",
    "data = BertData.create(\n",
    "    train_path,\n",
    "    valid_path, \n",
    "    vocab_file,\n",
    "    data_type=\"bert_uncased\",\n",
    "    max_seq_len=128,\n",
    "    batch_size=128\n",
    "    \n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from bailian_nlp.modules.models import bert_models\n",
    "reload(bert_models)\n",
    "\n",
    "model = bert_models.BertBiLSTMAttnCRF.create(\n",
    "    len(data.label2idx),\n",
    "    enc_hidden_dim=256\n",
    ")\n",
    "\n",
    "\n",
    "from bailian_nlp.modules.train import train\n",
    "reload(train)\n",
    "num_epochs = 10\n",
    "learner = train.NerLearner(model, data,\n",
    "                     best_model_path=model_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from importlib import reload\n",
    "from bailian_nlp.modules.models import bert_models\n",
    "reload(bert_models)\n",
    "\n",
    "model = bert_models.BertBiLSTMAttnCRF.create(\n",
    "    len(data.label2idx),\n",
    "    enc_hidden_dim=256\n",
    ")\n",
    "model.get_n_trainable_params()\n",
    "\n",
    "\n",
    "from bailian_nlp.modules.train import train\n",
    "reload(train)\n",
    "num_epochs = 2\n",
    "learner = train.NerLearner(model, data,\n",
    "                     best_model_path=model_pt,\n",
    "                     lr=0.001, clip=1.0, sup_labels=data.id2label,\n",
    "                     t_total=num_epochs * len(data.train_dl))\n",
    "\n",
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复训练\n",
    "\n",
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n",
    "tagger.init_env(for_train=True)\n",
    "\n",
    "data = tagger.learner.data\n",
    "learner = tagger.learner\n",
    "num_epochs = 1\n",
    "learner.load_model()\n",
    "learner.t_total = num_epochs * len(data.train_dl)\n",
    "learner.sup_labels = list(set(data.id2label[1:]) | set(learner.sup_labels))\n",
    "learner.fit(num_epochs, target_metric='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(num_epochs, target_metric='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data import bert_data\n",
    "reload(bert_data)\n",
    "dl = bert_data.get_bert_data_loader_for_predict(valid_path, learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load_model()\n",
    "preds = learner.predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.plot_metrics import get_bert_span_report\n",
    "clf_report = get_bert_span_report(dl, preds)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailian_nlp.released import pos\n",
    "from importlib import reload\n",
    "reload(pos)\n",
    "tagger = pos.PosTagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "text = '近日，编程猫（深圳点猫科技有限公司）正式对外宣布完成B轮1.2亿元融资。本轮融资由高瓴资本领投，清流资本、清晗基金跟投，天使轮投资者猎豹移动继续跟投。'\n",
    "# text = '未来编程教育产业将蓬勃发展，编程猫作为提供工具与内容的企业，有望长期处于行业领跑者地位。'\n",
    "# text = '美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司美年大健康产业（集团）有限公司始创于2004年,是中国健康体检和医疗服务集团,总部位于上海,深耕布局北京、深圳、沈阳、广州、成都、武汉、...'\n",
    "# text = '百炼智能百炼智能'\n",
    "# text = '高越君冯是聪'\n",
    "text = '周光明确否认CEO佟显侨和衡量推动发出公司公告'\n",
    "text = '周光明确否认CEO佟显侨和CTO衡量说的罪名'\n",
    "text = '董事'\n",
    "# text = '一言九鼎'\n",
    "# text = '客户包括雀巢、洲际酒店、瑞士航空、德意志银行、红牛、瑞士联合银行等世界知名公司。'\n",
    "# text = '药方越是多的，越表明病是难的于治疗'\n",
    "text = '2012-11-8 的客户包括：宝洁 、杜邦、强生、百事可 乐、3M 、三菱、吉列、通用医疗系统、美国 运通、雅芳、纽约银 行、百时美—施贵 宝、礼来、迪斯尼、纳贝斯克、纽约'\n",
    "res = tagger.cut(text)\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
